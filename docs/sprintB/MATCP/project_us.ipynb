{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# US009 \n",
    "\n",
    "## · Introduction\n",
    "\n",
    "###### This US deals with the analysis of water consumption in green spaces, using consumption data provided in a CSV file named \"water_consumption\". The objective of this analysis is to examine water consumption patterns over time and across different parks,calculates the total consumption and associated cost for each park, generates bar plots to visualize monthly water consumption, calculates statistics for parks with the highest and lowest consumption and identify possible outliers in the data. These insights are crucial for efficient water resource management and also for ensuring the environmental sustainability of green spaces.\n",
    "\n",
    "\n",
    "\n",
    "## · Code and results"
   ],
   "id": "caa56b3a63b86ac8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T07:50:21.640229Z",
     "start_time": "2024-05-21T07:50:20.670043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Variables\n",
    "# PATH_FILE = input('Enter the path of the file (water consumption.csv): ')\n",
    "\n",
    "PATH_FILE = \"water_consumption.csv\"\n",
    "WTPRC_1000M3 = 0.7\n",
    "WTCONSUPTIONUPTO = 1000\n",
    "WTPRC_FEE = 0.15\n",
    "FIRST_MONTH = 1\n",
    "LAST_MONTH = 12\n",
    "CLASSES10 = 10\n",
    "CLASSES100 = 100\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "##Reading file \"water_consumption.csv\"\n",
    "data = pd.read_csv(PATH_FILE, sep=\";\")\n",
    "data['Consumption'] = data['Consumption'].str.replace(',', '.')\n",
    "data['Consumption'] = pd.to_numeric(data['Consumption'], errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "#WaterCost by month and park\n",
    "\n",
    "def calculate_cost(Consumption):\n",
    "    if Consumption <= WTCONSUPTIONUPTO:\n",
    "        return Consumption * WTPRC_1000M3\n",
    "    else:\n",
    "        return (WTCONSUPTIONUPTO * WTPRC_1000M3) + ((Consumption - WTCONSUPTIONUPTO) * WTPRC_1000M3 * WTPRC_FEE)\n",
    "\n",
    "data['Total_Consumption'] = data.groupby(['Park', 'Year', 'Month'])['Consumption'].transform('sum')\n",
    "consumptionInfo = data.groupby(['Park', 'Year', 'Month'])['Total_Consumption'].unique().explode().reset_index(name='Total_Consumption')\n",
    "consumptionInfo['Cost'] = consumptionInfo['Total_Consumption'].apply(calculate_cost)\n",
    "cost_summary = consumptionInfo.loc[:, [\"Park\", \"Year\", \"Month\", \"Cost\"]]\n",
    "print(\"· The cost of consumption of water by each park:\\n\")\n",
    "print(cost_summary)\n",
    "\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Imports\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#Variables\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# PATH_FILE = input('Enter the path of the file (water consumption.csv): ')\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"· I ) Barplot representing monthly water consumption\\n\")\n",
    "\n",
    "# Get unique years and parks\n",
    "years = data[\"Year\"].unique()\n",
    "parks = data[\"Park\"].unique()\n",
    "\n",
    "# Input year\n",
    "year = int(input(\"Enter the year: \"))\n",
    "while year not in years:\n",
    "    year = int(input(f\"Enter an existing year {years}: \"))\n",
    "\n",
    "# Input start month\n",
    "start_month = int(input(\"Enter the start month: \"))\n",
    "while start_month < FIRST_MONTH or start_month > LAST_MONTH:\n",
    "    start_month = int(input(\"INVALID: Enter a valid start month: \"))\n",
    "\n",
    "# Input end month\n",
    "end_month = int(input(\"Enter the end month: \"))\n",
    "while end_month < FIRST_MONTH or end_month > LAST_MONTH:\n",
    "    end_month = int(input(\"INVALID: Enter a valid end month: \"))\n",
    "\n",
    "# Ensure start month is less than or equal to end month\n",
    "while start_month > end_month:\n",
    "    start_month = int(input(f\"INVALID: Start month > End month ({start_month} > {end_month})\\nEnter a valid start month: \"))\n",
    "\n",
    "# Input park name\n",
    "parkId = input(\"Enter the Park name: \").strip()\n",
    "while parkId not in parks:\n",
    "    parkId = input(\"INVALID: Enter an existing Park name: \").strip()\n",
    "\n",
    "# Filter data for the specified conditions\n",
    "filtered_data = consumptionInfo[(consumptionInfo['Park'].str.lower() == parkId.lower()) & \n",
    "                                (consumptionInfo['Year'] == year) & \n",
    "                                (consumptionInfo['Month'] >= start_month) & \n",
    "                                (consumptionInfo['Month'] <= end_month)]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Month\", y=\"Total_Consumption\", data=filtered_data)\n",
    "plt.title(f'Monthly Water Consumption for {parkId} in {year}')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Consumption')\n",
    "plt.xticks(range(start_month-1, end_month), [f'{i}' for i in range(start_month, end_month+1)])\n",
    "plt.show()"
   ],
   "id": "27ed4e349bda91b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"· II ) Average Monthly Cost for Each Specified Park:\\n\")\n",
    "###########################################\n",
    "\n",
    "numberOfParks = int(input(\"Enter the number of Parks to see average monthly cost: \"))\n",
    "while numberOfParks > len(parks) or numberOfParks < 0:\n",
    "    numberOfParks = int(input(f\"Enter a valid number of Parks (existent parks {len(parks):.0f}): \"))\n",
    "\n",
    "if numberOfParks  != 0: \n",
    "    idParksAverage = []\n",
    "    for i in range(numberOfParks):\n",
    "        id = input(f\"Enter the Park name (nº:{i+1}) to see average monthly cost: \")\n",
    "        while id not in parks:\n",
    "            id = input(f\"Enter a existent Park (nº:{i+1}): \")\n",
    "        while idParksAverage.__contains__(id) or id not in parks:\n",
    "            id = input(f\"Duplicate park, enter a new one (nº:{i+1}): \")\n",
    "        idParksAverage.append(id)\n",
    "    \n",
    "    # Calculate average monthly cost for specified parks\n",
    "    average_cost_per_park = cost_summary.groupby('Park')['Cost'].mean()\n",
    "    \n",
    "    # Display average monthly cost for specified parks\n",
    "    for park_id in idParksAverage:\n",
    "        if park_id in average_cost_per_park.index:\n",
    "            print(f\"Park ID: {park_id}\\n ·Average Monthly Cost: {average_cost_per_park[park_id]:.2f}€\")\n",
    "else:\n",
    "    print(\"ATTENTION: 0 parks selected, no average monthly cost\\n\")\n",
    "    \n"
   ],
   "id": "8591a0defabf64e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"· III )\")\n",
    "###########################################\n",
    "\n",
    "# Statistics\n",
    "print(\"·· 1) Calculate statistics for the park/s with the highest and lowest consumption.\\n\")\n",
    "\n",
    "##HIGHEST\n",
    "print(\"[ Highest consumption park/s ]\")\n",
    "print(\"  --------------------------\\n\")\n",
    "highest_consumption_park = data.groupby('Park')['Consumption'].max()\n",
    "maxValue = highest_consumption_park.max()\n",
    "\n",
    "for park_id, value in highest_consumption_park.items():\n",
    "    if value == maxValue:\n",
    "        park_with_highest_consumption = park_id\n",
    "        # Calculate statistics for the park with the highest consumption\n",
    "        highest_consumption_stats = data[data['Park'] == park_with_highest_consumption]['Consumption'].agg(['mean', 'median', 'std', 'skew'])\n",
    "        highest_consumption_stats = highest_consumption_stats.rename(lambda x: f'{park_with_highest_consumption}_{x}')\n",
    "        print(f\"Statistics for the park ({park_with_highest_consumption} - {highest_consumption_park.max():.2f} m3):\")\n",
    "        print(highest_consumption_stats.to_string())\n",
    "        print()\n",
    "\n",
    "\n",
    "##lOWEST\n",
    "print(\"[ Lowest consumption park/s ]\")\n",
    "print(\"  -------------------------\\n\")\n",
    "\n",
    "def min_consumption_without_zero(group):\n",
    "    non_zero_values = group[group != 0]  # Exclude zero values\n",
    "    if non_zero_values.empty:\n",
    "        return 0  # Return 0 if all values are zero\n",
    "    else:\n",
    "        return non_zero_values.min()\n",
    "\n",
    "\n",
    "lowest_consumption_park = data.groupby('Park')['Consumption'].apply(min_consumption_without_zero)\n",
    "minValue = lowest_consumption_park.min()\n",
    "\n",
    "for park_id, value in lowest_consumption_park.items():\n",
    "    if value == minValue and (not maxValue == highest_consumption_park[park_id].max()):\n",
    "        park_with_lowest_consumption = park_id\n",
    "        # Calculate statistics for the park with the lowest consumption\n",
    "        lowest_consumption_stats = data[data['Park'] == park_with_lowest_consumption]['Consumption'].agg(['mean', 'median', 'std', 'skew'])\n",
    "        lowest_consumption_stats = lowest_consumption_stats.rename(lambda x: f'{park_with_lowest_consumption}_{x}')\n",
    "        print(f\"Statistics for the park ({park_with_lowest_consumption} - {lowest_consumption_park.min():.2f} m3):\")\n",
    "        print(lowest_consumption_stats.to_string())\n",
    "        print()"
   ],
   "id": "afceef246e042ab1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"· III )\")\n",
    "###########################################\n",
    "\n",
    "print(\"·· 2) Build relative and absolute frequency tables.\\n\")\n",
    "C = 5\n",
    "\n",
    "##HIGHEST\n",
    "\n",
    "\n",
    "print(\"[ Highest consumption park/s ]\")\n",
    "print(\"  --------------------------\\n\\n\")\n",
    "for park_id, value in highest_consumption_park.items():\n",
    "    if value == maxValue:\n",
    "        park_with_highest_consumption = park_id\n",
    "        park_with_highest_consumption_data = data[data['Park'] == park_with_highest_consumption]['Consumption']\n",
    "        \n",
    "        n_highest = len(park_with_highest_consumption_data)\n",
    "        data_min_highest = park_with_highest_consumption_data.min()\n",
    "        data_max_highest = park_with_highest_consumption_data.max()\n",
    "        \n",
    "        # Divide em 5 classes\n",
    "        class_interval_highest = (data_max_highest - data_min_highest) / C \n",
    "         # Limite inferior e superior de cada classe\n",
    "        class_limits_highest = [data_min_highest + i * class_interval_highest for i in range(C+1)] \n",
    "        #Intervalos\n",
    "        classes_highest = [[round(class_limits_highest[i],2) ,round(class_limits_highest[i+1],2)] for i in range(C)]\n",
    "        \n",
    "        #FQ absoluta\n",
    "        absolute_frequencies_highest = [sum(1 for value in park_with_highest_consumption_data if class_limits_highest[i] <= value < class_limits_highest[i+1]) for i in range(C)]\n",
    "        #FQ relativa\n",
    "        relative_frequencies_highest = [round((freq / n_highest) *100,2) for freq in absolute_frequencies_highest] \n",
    "        #FQ acumulada\n",
    "        acumulate_frequencies_highest = []\n",
    "        soma = 0\n",
    "        for i in absolute_frequencies_highest:\n",
    "            soma += i\n",
    "            acumulate_frequencies_highest.append(soma)\n",
    "        \n",
    "        dados = {\n",
    "            \"Classes\": classes_highest,\n",
    "            \"Freq_abs\": absolute_frequencies_highest,\n",
    "            \"Freq_rel(%)\": relative_frequencies_highest,\n",
    "            \"Freq_acum\": acumulate_frequencies_highest\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(dados)\n",
    "        print(f\"Park : {park_id}\\n\")\n",
    "        print(df)\n",
    "        print(\"\\n\")\n",
    "  \n",
    "  \n",
    "##lOWEST\n",
    "print(\"[ Lowest consumption park/s ]\")\n",
    "print(\"  -------------------------\\n\\n\")   \n",
    "\n",
    "for park_id, value in lowest_consumption_park.items():\n",
    "    if value == minValue and (not maxValue == highest_consumption_park[park_id].max()):    \n",
    "        park_with_lowest_consumption = park_id\n",
    "        park_with_lowest_consumption_data = data[data['Park'] == park_with_lowest_consumption]['Consumption']\n",
    "        n_lowest = len(park_with_lowest_consumption_data)\n",
    "        \n",
    "        data_min_lowest = park_with_lowest_consumption_data.min()\n",
    "        data_max_lowest = park_with_lowest_consumption_data.max()\n",
    "        # Divide em 5 classes\n",
    "        class_interval_lowest = (data_max_lowest - data_min_lowest) / C  \n",
    "        class_limits_lowest = [data_min_lowest + i * class_interval_lowest for i in range(C+1)]  # Limite inferior e superior de cada classe        \n",
    "        classes_highest = [[round(class_limits_lowest[i],2) ,round(class_limits_lowest[i+1],2)] for i in range(C)]\n",
    "        \n",
    "        #FQ absoluta\n",
    "        absolute_frequencies_highest = [sum(1 for value in park_with_lowest_consumption_data if class_limits_lowest[i] <= value < class_limits_lowest[i+1]) for i in range(C)]\n",
    "        #FQ relativa\n",
    "        relative_frequencies_highest = [round((freq / n_lowest) *100,2) for freq in absolute_frequencies_highest] \n",
    "        #FQ acumulada\n",
    "        acumulate_frequencies_highest = []\n",
    "        soma = 0\n",
    "        for i in absolute_frequencies_highest:\n",
    "            soma += i\n",
    "            acumulate_frequencies_highest.append(soma)\n",
    "        \n",
    "        dados = {\n",
    "            \"Classes\": classes_highest,\n",
    "            \"Freq_abs\": absolute_frequencies_highest,\n",
    "            \"Freq_rel(%)\": relative_frequencies_highest,\n",
    "            \"Freq_acum\": acumulate_frequencies_highest\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(dados)\n",
    "        \n",
    "        print(f\"Park : {park_id}\\n\")\n",
    "        print(df)\n",
    "        print(\"\\n\")"
   ],
   "id": "f6c1a9ff24f84c79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"· III )\")\n",
    "###########################################\n",
    "print(\"·· 3) Find outliers.\\n\")\n",
    "\n",
    "\n",
    "# Group the data by each park\n",
    "grouped_data = data.groupby('Park')\n",
    "\n",
    "# Iterate over each group (park)\n",
    "for park, group in grouped_data:\n",
    "    # Calculate median and interquartile range (IQR)\n",
    "    median = group['Consumption'].median()\n",
    "    q1 = group['Consumption'].quantile(0.25)\n",
    "    q3 = group['Consumption'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Define outlier range\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = group[(group['Consumption'] < lower_bound) | (group['Consumption'] > upper_bound)]\n",
    "    \n",
    "    # Print results\n",
    "    if not outliers.empty:\n",
    "        print(f\"Park ID: {park}:\\n\")\n",
    "        print(outliers)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"No outliers found for {park}\\n\")"
   ],
   "id": "63eace6461876d3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"· III )\")\n",
    "###########################################\n",
    "print(\"·· 4) Histograms\\n\")\n",
    "\n",
    "for park_id, value in highest_consumption_park.items():\n",
    "    if value == maxValue: \n",
    "        consumption_park = data[data['Park'] == park_id]['Consumption']\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(consumption_park, bins=CLASSES10, color='skyblue', alpha=0.8)\n",
    "        plt.title(f'Histograma com 10 Classes : Highest Value\\n Park : {park_id}')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Consumption')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(consumption_park, bins=CLASSES100, color='skyblue', alpha=0.8)\n",
    "        plt.title(f'Histograma com 100 Classes : Highest Value\\n Park : {park_id}')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Consumption')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        \n",
    "for park_id, value in lowest_consumption_park.items():\n",
    "    if value == minValue and (not maxValue == highest_consumption_park[park_id].max()): \n",
    "        consumption_park = data[data['Park'] == park_id]['Consumption']\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(consumption_park, bins=CLASSES10, color='skyblue', alpha=0.8)\n",
    "        plt.title(f'Histograma com 10 Classes : Lowest Value\\n Park : {park_id}')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Consumption')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(consumption_park, bins=CLASSES100, color='skyblue', alpha=0.8)\n",
    "        plt.title(f'Histograma com 100 Classes : Lowest Value\\n Park : {park_id}')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Consumption')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "825ed9d36e40dd5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## · Formulas (Latex)\n",
    "\n",
    "$$\n",
    "\\text{Cost of water} = \n",
    "\\begin{cases} \n",
    "\\text{Consumption} \\times 0.7 & \\text{if Consumption} \\leq 1000 \\\\\n",
    "(1000 \\times 0.7) + ((\\text{Consumption} - 1000) \\times 0.7 \\times 0.15) \\text{     } & \\text{if } 1000 \\leq \\text{Consumption}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Mean} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Median} = \n",
    "\\begin{cases} \n",
    "\\text{Middle value of the sorted dataset    } & \\text{if $n$ is odd} \\\\\n",
    "\\frac{\\text{Sum of the two middle values}}{2   } & \\text{if $n$ is even}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Standard Deviation} = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Coefficient of Skewness} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^3}{n \\times \\sigma^3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Absolute Frequency} = {\\sum_{i=1}^{c} n_i} = n\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Relative Frequency} = f_i = \\frac{{n_i}}{{n}}\n",
    "$$\n",
    "\n",
    "\n",
    "##### Where:\n",
    "\n",
    "$$\\( \\bar{x} \\)\\text{ - } is \\text{ } the \\text{ } mean$$\n",
    "$$\\( \\sigma \\)\\text{ - } is \\text{ } the\\text{ } standard \\text{ }deviation\\text{ }$$\n",
    "$$\\( n \\)\\text{ - } is\\text{ }  the\\text{ }  number\\text{ }  of\\text{ }  data\\text{ }  points$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## · Analysis and Interpretation of the Results:\n",
    "\n",
    "\n",
    "\n",
    "#####   1) Cost of Water Consumption per Park:\n",
    " Analyzing the cost of water consumption per park provides a clear understanding of the expenses associated with maintaining these green spaces. This helps identify which parks have the highest water consumption costs and can guide decisions regarding resource allocation and implementation of conservation measures.\n",
    "\n",
    "#####  2) Monthly Water Consumption Barplot:\n",
    "\n",
    "Bar plots representing monthly water consumption allow visualizing seasonal patterns in water consumption in each park. This can reveal peak consumption months.\n",
    "\n",
    "#####  3) Average Monthly Cost per Park:\n",
    "\n",
    "Calculating the average monthly cost per park offers an overview of the average expenses of each park over time. This assists in identifying cost trends and comparing the performance of different parks in terms of water usage efficiency.\n",
    "\n",
    "#####  4) Consumption Statistics for Parks with Highest and Lowest Consumption:\n",
    "\n",
    "This provides a detailed understanding of the distributions of water consumption in each park. This includes measures of central tendency (mean, median), dispersion (standard deviation), and distribution shape (skewness). These statistics help identify parks with extreme consumption patterns and understand the variability in the data.\n",
    "\n",
    "#####  5) Relative and Absolute Frequency Tables:\n",
    "\n",
    "Relative and absolute frequency tables offer a detailed view of the distribution of water consumption in specific intervals for parks with the highest and lowest consumption. This helps identify the most common consumption intervals and assess the uniformity or disparity in consumption distribution among different parks.\n",
    "\n",
    "##### 6) Outlier Detection:\n",
    "\n",
    "Identifying outliers in water consumption data allows pinpointing unusual observations that may indicate issues such as leaks, measurement errors, or anomalous consumption patterns. This aids in identifying areas requiring further investigation or corrective action.\n",
    "\n",
    "#####  7) Histograms with 10 and 100 Classes:\n",
    "\n",
    "Histograms with different numbers of classes provide a visual representation of the distribution of water consumption in each park. This allows visualizing the shape of the distribution, identifying clustering patterns, and assessing the uniformity of consumption distribution across different intervals.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## · Conclusion\n",
    "\n",
    "\n",
    "This data analysis revealed interesting water consumption patterns in different parks over time. Additionally, outliers were identified in some parks, indicating cases of excessive or unusual consumption. The generated histograms provide a clear visualization of the distribution of water consumption in each park, allowing for comparison across different data classes. These insights are crucial for efficient water resource management, enabling the identification of areas that require greater attention and intervention\n",
    "\n"
   ],
   "id": "d08e9613082d65d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### US0010 \n",
    "\n",
    "#### · Introduction\n",
    "This US has the objective of knowing the preferences of the users in the park, for that we must record the usage of each equipment in a csv file and then, display them in a pie chart with the percentage of usage of each piece of equipment.\n",
    "\n",
    "#### · Code and results"
   ],
   "id": "389e008fbd279cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = \"EquipmentUsed.csv\"\n",
    "\n",
    "dataFrame = pd.read_csv(file)\n",
    "\n",
    "equipmentCount = dataFrame.apply(pd.Series.value_counts).sum(axis=1)\n",
    "\n",
    "equipmentPercentage = (equipmentCount / equipmentCount.sum()) * 100\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(equipmentPercentage, labels=equipmentPercentage.index, autopct='%1.1f%%', startangle=0)\n",
    "plt.axis('equal')\n",
    "plt.title('Percentage of Equipment Usage\\n\\n')\n",
    "plt.show()"
   ],
   "id": "3edd13be29af802d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### · Formulas\n",
    "\n",
    "$$\n",
    "\n",
    "\\text{n} = (\\frac{{u}}{{t}}) * 100\n",
    "\n",
    "$$\n",
    "\n",
    "\n",
    "##### Where:\n",
    "\n",
    "$$\\( \\text{n} \\)\\text{ - percentage of usage of a equipment } $$\n",
    "\n",
    "$$\\( \\text{u} \\)\\text{ - number of times certain equipment was used } $$\n",
    "\n",
    "$$\\( \\text{t} \\)\\text{ - total number of equipment used}  $$\n",
    "\n",
    "\n",
    "\n",
    "## · Analysis and Interpretation of the Results:\n",
    "This code starts by asking the user to write the name of the csv file to be read. Creates a dataFrame from the data, counts the number of times each equipment was used, and then finishes by generating a pie chart to visualize the percentage of equipment usage.\n",
    "\n",
    "After reading the data from the file using Pandas and a dataFrame, \"dataFrame.apply(pd.Series.value_counts).sum(axis=1)\" counts the number of times each equipment was used and stores it in equipmentCount.\n",
    "\"equipmentPercentage = (equipmentCount / equipmentCount.sum()) * 100\" uses the equipmentCount from earlier and then divides it by the total number of equipments used, finally it multiples by 100 to make the equipmentPercentage.\n",
    "At last, it displays the pie chart using the data that was read using matplotlib.pyplot.\n",
    "\n",
    "Overall, this script allows users to analyze equipment usage data from a csv file and provides a representation of the distribution of equipment usage percentages.\n",
    "The graph that results from this code shows the percentage of usage of each equipment from the list given.\n"
   ],
   "id": "2cd0691d00ee0a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### US011 \n",
    "\n",
    "#### · Introduction\n",
    "\n",
    "This report presents an analysis of park visitor data extracted from a CSV file. Utilizing Python's pandas and matplotlib libraries, the data is processed to determine variable types and calculate proportions of park visitors recommending the park across different age groups. Additionally, boxplots are generated to visualize the monthly frequency of park use categorized by age groups.\n",
    "\n",
    "\n",
    "#### · Code and results\n",
    "\n"
   ],
   "id": "16c3ff286cf0c04c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"Inquiry.csv\", delimiter=';')\n",
    "\n",
    "child = []\n",
    "adult = []\n",
    "senior = []\n",
    "\n",
    "for index, escalao in enumerate(data['Escalao']):\n",
    "    if escalao == 1 :\n",
    "        child.append(data['Y/N'][index])\n",
    "    elif escalao == 2 :\n",
    "        adult.append(data['Y/N'][index])\n",
    "    elif escalao == 3 :\n",
    "        senior.append(data['Y/N'][index])\n",
    "\n",
    "child = pd.Series(child)\n",
    "adult = pd.Series(adult)\n",
    "senior = pd.Series(senior)\n",
    "\n",
    "child_group_recommendation_proportion = child.eq('Y').mean() if len(child) > 0 else 0.0\n",
    "adult_group_recommendation_proportion = adult.eq('Y').mean() if len(adult) > 0 else 0.0\n",
    "senior_group_recommendation_proportion = senior.eq('Y').mean() if len(senior) > 0 else 0.0\n",
    "\n",
    "print(f\"Escalao - int | Y/N - String | Visits - int\\n\")\n",
    "\n",
    "print(f\"Child group recommendation proportion: {child_group_recommendation_proportion*100:.3}%\")\n",
    "print(f\"Adult group recommendation proportion: {adult_group_recommendation_proportion*100:.3}%\")\n",
    "print(f\"Senior group recommendation proportion: {senior_group_recommendation_proportion*100:.3}%\")\n",
    "\n",
    "child_data = data[data['Escalao'] == 1]\n",
    "adult_data = data[data['Escalao'] == 2]\n",
    "senior_data = data[data['Escalao'] == 3]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([child_data['Visits'], adult_data['Visits'], senior_data['Visits']],\n",
    "            labels=['Child (<= 15)', 'Adult (16-65)', 'Senior (>= 66)'])\n",
    "plt.title('Monthly Visits Frequency by Age Group')\n",
    "plt.xlabel('Age Groups')\n",
    "plt.ylabel('Visits')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "7a58a5a235496bc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This formula calculates the mean of recomendations of each age group:\n",
    "$$\n",
    "\\text{Mean} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n",
    "$$\n",
    "\n",
    "Shows the range of each age group:\n",
    "$$\n",
    "\\text{Age range} = \n",
    "\\begin{cases} \n",
    "\\text{Child} & \\text{if } \\text{Age} \\leq 15 \\\\\n",
    "\\text{Adult} & \\text{if } 16 \\leq \\text{Age} \\leq 65 \\\\\n",
    "\\text{Senior} & \\text{if } \\text{Age} \\geq 66\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "General proportion formula:\n",
    "$$\n",
    "\\text{Proportion} = \\frac{\\text{Number of users who recommend the park}}{\\text{Total number of users in the age group}}\n",
    "$$\n",
    "\n",
    "Proportion formula of each age group:\n",
    "$$\n",
    "\\text{Child Group Proportion} = \\frac{\\text{Number of children recommending the park}}{\\text{Total number of children}}\\\\\n",
    "\\text{Adult Group Proportion} = \\frac{\\text{Number of adults recommending the park}}{\\text{Total number of adults}}\\\\\n",
    "\\text{Senior Group Proportion} = \\frac{\\text{Number of seniors recommending the park}}{\\text{Total number of seniors}}\n",
    "$$\n",
    "\n",
    "#### · Analysis and Interpretation of the Results:\n",
    "The provided code conducts an analysis of a dataset stored in a CSV file named \"Inquiry.csv\", focusing on age groups categorized as Child, Adult, and Senior. It first calculates the proportion of individuals within each age group who received a recommendation. It also graphs the distribution of monthly visit frequencies for each age group, using a boxplot. The analysis highlights the fact that the senior population receives greater numbers of visits, having a major impact on recommendations.\n",
    "\n",
    "\n",
    "Also by analysing the graph we can observe the following topics:\n",
    "\n",
    "**Median (line in the middle of the box):** The median is represented by the line that divides the box in half. It indicates the central value of the data. Being three the median value of Child, five of adult and seven of senior.\n",
    "\n",
    "**Quartiles (box boundaries):** The box of the boxplot is bounded by quartiles. The first quartile (Q1) is the value below which 25% of the data lies, while the third quartile (Q3) is the value below which 75% of the data lies. The difference between Q3 and Q1 is called the interquartile range (IQR), which can be used to measure data dispersion.\n",
    "\n",
    "**Whiskers (lines extending from the box):** The lines extending from the sides oaf the box represent the boundaries of the data not considered outliers. The length of the lines may vary depending on the implementation but usually follows a statistical rule. For example, they might be 1.5 times the IQR. Any value outside of these limits is considered an outlier.\n",
    "\n",
    "**Outliers (points outside the whiskers):** Individual points falling outside the whisker limits are considered outliers. They may indicate extreme values or errors in the data.\n",
    "\n"
   ],
   "id": "e4a7bab0d4cfde38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# · Self Evaluation\n",
    "####\n",
    "#### 1230444 (Romeu Xu)            - 20%\n",
    "#### 1230839 (Emmanuel Almeida)    - 20%\n",
    "#### 1230564 (Francisco Santos)    - 20%\n",
    "#### 1231498 (Paulo Mendes)        - 20%\n",
    "#### 1231274 (Jorge Ubaldo)        - 20%"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd149ce906d4624d"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "82da463dd5ef79af",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
